{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a Successful New York Times Article Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython Process Book\n",
    "\n",
    "An important part of your project is your iPython process book. Your process book details your steps in developing your solution, including how you collected the data, alternative solutions you tried, describing statistical methods you used, and the insights you got. Equally important to your final results is how you got there! Your process book is the place you describe and document the space of possibilities you explored at each step of your project. We strongly advise you to include many visualizations in your process book.Your process book should include the following topics. Depending on your project type the amount of discussion you devote to each of them will vary:\n",
    "\n",
    "\n",
    "<strong>Overview and Motivation</strong>: Provide an overview of the project goals and the motivation for it. Consider that this will be read by people who did not see your project proposal.\n",
    "\n",
    "<strong>Related Work</strong>: Anything that inspired you, such as a paper, a web site, or something we discussed in class.\n",
    "\n",
    "<strong>Initial Questions</strong>: What questions are you trying to answer? How did these questions evolve over the course of the project? What new questions did you consider in the course of your analysis?\n",
    "\n",
    "<strong>Data</strong>: Source, scraping method, cleanup, storage, etc.\n",
    "\n",
    "<strong>Exploratory Data Analysis</strong>: What visualizations did you use to look at your data in different ways? What are the different statistical methods you considered? Justify the decisions you made, and show any major changes to your ideas. How did you reach these conclusions?\n",
    "\n",
    "<strong>Final Analysis</strong>: What did you learn about the data? How did you answer the questions? How can you justify your answers?\n",
    "\n",
    "<strong>Presentation</strong>: Present your final results in a compelling and engaging way using text, visualizations, images, and videos on your project web site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As one of the most popular online news entities*, The New York Times (NYT) attracts thousands of unique visitors each day to its website, nytimes.com. Users who visit the site can provide their thoughts and reactions to published content in the form of comments. \n",
    "\n",
    "Users can interact with published comments, by either replying back or recommending a comment (i.e., similar to a 'like' on Facebook) as high quality. The very best comments are picked by NYT staff and marked as NYT picks. We noticed that highly recommended comments and NYT picks comments tend to be significantly longer, more thoughtful, and of high quality compared to the majority of other internet comments.\n",
    "\n",
    "We aim to examine the relationship between comment success (i.e., number of recommendations by other users and if selected as a NYT pick) and various features of the comment itself. This way, we will be able to produce a model that can predict the success of a given comment. This is important as the comment section enables visitors to further interact with NYT content. The comment section is a discussion board for the exchange of ideas, thoughts, and opinions. \n",
    "\n",
    "Successful comments can become more visible on the site. Thus, understanding what could make a succesfful comment is important for both content providers and commentors. Providers can provide better comment guidelines and suggestions to its audience in an attempt to increase the quality of content exchanged on message boards. Additionally, since a NYT moderator must manually approve or reject each submitted comment, a provisional comment ranking system could enable a quicker means to approve good comments. An effective prediction system could also be used in an automated comment recommender to help steer users toward higher quality content. \n",
    "\n",
    "*http://www.journalism.org/media-indicators/digital-top-50-online-news-entities-2015/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We are all avid readers of the New York Times and find the comment section to be a great launching pad for further discussion and debate. Andrew was on the leadership board of The Harvard Crimson, so he has experienced journalism first-hand.\n",
    "\n",
    "While we have not encountered any work that specifically looks at what makes a successful comment on a news site such as that of the NYT, our work is built upon methods that are not new. Speciifcally, we aim to employ sentiment analysis and latent dirichlet allocation (LDA) in our analysis. \n",
    "\n",
    "Insert summary and link to a sentiment analysis paper\n",
    "\n",
    "Insert summary and link to LDA paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Our main goal is to predict how many recommendations a comment it will receive and if it will be designated as a NYT pick based on the comment's text. Additionally, we aim to quantitatively examine what makes a successful and highly rated comment. For example, do longer comments fare better? Does average word or sentence length play a role? Does the sentiment of the comment have an effect?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained the comment data from the New York Times' API. The API is well-documented and operates similar to that of the Huffington Post API that was used earlier in the course. We gathered 300 comments per day from Nov 1, 2014 to Nov 15, 2015. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import requests, time, simplejson, sys\n",
    "import pandas as pd\n",
    "\n",
    "def perdelta(start, end, delta):\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        yield curr\n",
    "        curr += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrape 300 comments per day from Nov. 1, 2014 to Oct. 31, 2015\n",
    "for da in perdelta(date(2015, 2, 21), date(2015, 11, 1), timedelta(days=1)):\n",
    "    comments = []\n",
    "    print da\n",
    "    skip = False\n",
    "    gotany = True\n",
    "    for i in range(12): # collect 25 comments at a time for 12 times. 25*12 = 300 comments\n",
    "        if not skip:\n",
    "            success = False\n",
    "            count = 0\n",
    "            url = ('http://api.nytimes.com/svc/community/v3/user-content/' +\n",
    "                   'by-date.json?api-key=KEY&date=' + str(da) +\n",
    "                   '&offset=' + str(25*i))\n",
    "            while not success:\n",
    "                comments_data = requests.get(url)\n",
    "                try:\n",
    "                    data = simplejson.loads(comments_data.content)\n",
    "                    success = True # go to the next offset\n",
    "                    for d in data['results']['comments']:\n",
    "                        comments.append(d)\n",
    "                    time.sleep(2)\n",
    "                except:\n",
    "                    print 'error on {}'.format(str(da))\n",
    "                    print url\n",
    "                    count += 1\n",
    "                    if count > 3:\n",
    "                        success = True # not really\n",
    "                        skip = True # just skip to the next day\n",
    "                        if i == 0:\n",
    "                            gotany = False # if we didn't get any comments from that day\n",
    "                    time.sleep(2)\n",
    "    if gotany:      \n",
    "        filestr = 'comments {}.json'.format(str(da))\n",
    "        with open(filestr, 'w') as f:\n",
    "            simplejson.dump(comments, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine all the JSON lists into single JSON file\n",
    "allcomments = []\n",
    "for d in perdelta(date(2014, 1, 1), date(2015, 12, 31), timedelta(days=1)):\n",
    "    try:\n",
    "        with open('json_files/comments {}.json'.format(str(d))) as f:\n",
    "            c = simplejson.load(f)\n",
    "            allcomments.extend(c)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the aggregated JSON file\n",
    "with open ('comment_data.json', 'w') as f:\n",
    "    simplejson.dump(allcomments, f)\n",
    "with open ('comment_data.json', 'r') as f:\n",
    "    comments = simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert data into a dataframe \n",
    "commentsdicts=[]\n",
    "for c in comments:\n",
    "    d={}\n",
    "    d['approveDate']=c['approveDate']\n",
    "    d['assetID']=c['assetID']\n",
    "    d['assetURL']=c['assetURL']\n",
    "    d['commentBody']=c['commentBody']\n",
    "    d['commentID']=c['commentID']\n",
    "    d['commentSequence']=c['commentSequence']\n",
    "    d['commentTitle']=c['commentTitle']\n",
    "    d['createDate']=c['createDate']\n",
    "    d['editorsSelection']=c['editorsSelection']\n",
    "    d['lft']=c['lft']\n",
    "    d['parentID']=c['parentID']\n",
    "    d['recommendationCount']=c['recommendationCount']\n",
    "    d['replies']=c['replies']\n",
    "    d['replyCount']=c['replyCount']\n",
    "    d['rgt']=c['rgt']\n",
    "    d['status']=c['status']\n",
    "    d['statusID']=c['statusID']    \n",
    "    d['updateDate']=c['updateDate']        \n",
    "    d['userDisplayName']=c['userDisplayName']\n",
    "    d['userID']=c['userID']\n",
    "    d['userLocation']=c['userLocation']\n",
    "    #d['userTitle']=c['userTitle']\n",
    "    #d['userURL']=c['userURL']    \n",
    "    commentsdicts.append(d)  \n",
    "commentsdf=pd.DataFrame(commentsdicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
